name: Sanity Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          
      - name: Run tests with Allure
        run: |
          mkdir -p allure-results
          # Create Python 3.10 compatibility patch
          cat > patch_collections.py << EOF
          #!/usr/bin/env python3
          # Patch for Python 3.10+ to run pytest with allure
          import collections, collections.abc, sys
          import pytest
          import os

          # Apply the patches for all needed classes
          collections.Mapping = collections.abc.Mapping
          collections.Sequence = collections.abc.Sequence
          print("Patches applied: collections.Mapping and collections.Sequence")

          # Create allure results directory
          if not os.path.exists("allure-results"):
              os.makedirs("allure-results")

          # Run pytest with allure reporting
          sys.exit(pytest.main(["tests/", "--alluredir=allure-results"]))
          EOF
          
          # Run tests with our patch
          python patch_collections.py
        continue-on-error: true
        
      - name: Generate Allure report
        uses: simple-elf/allure-report-action@master
        if: always()
        with:
          allure_results: allure-results
          allure_report: allure-report
          
      - name: Parse test metrics
        if: always()
        run: |
          echo "Parsing test metrics..."
          
          # Get test results from Allure JSON files
          TOTAL_TESTS=$(find allure-results -name "*.json" | grep -v "environment\|categories\|executor" | wc -l)
          PASSED_TESTS=$(grep -l '"status":"passed"' allure-results/*.json | wc -l)
          FAILED_TESTS=$((TOTAL_TESTS - PASSED_TESTS))
          
          # Calculate pass rate
          if [ $TOTAL_TESTS -eq 0 ]; then
            PASS_RATE=0
          else
            PASS_RATE=$(echo "scale=2; ($PASSED_TESTS * 100) / $TOTAL_TESTS" | bc)
          fi
          
          # Get critical tests count
          CRITICAL_TESTS=$(grep -l "critical_workflow" allure-results/*.json | wc -l)
          
          # Get test duration from GitHub Actions timing
          START_TIME=$(date +%s)
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          # Create metrics JSON
          cat > metrics.json << EOF
          {
            "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "total_tests": $TOTAL_TESTS,
            "passed_tests": $PASSED_TESTS,
            "failed_tests": $FAILED_TESTS,
            "pass_rate": $PASS_RATE,
            "duration_seconds": $DURATION,
            "critical_tests_count": $CRITICAL_TESTS,
            "run_id": "${{ github.run_id }}",
            "repository": "${{ github.repository }}",
            "branch": "${{ github.ref }}"
          }
          EOF
          
          cat metrics.json
          
      - name: Upload metrics artifact
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: metrics
          path: metrics.json
          
      - name: Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./allure-report
          destination_dir: allure-report/${{ github.run_number }}
          keep_files: true 