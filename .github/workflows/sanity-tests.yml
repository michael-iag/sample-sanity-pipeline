name: Sanity Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          # Install jq for JSON processing
          sudo apt-get install -y jq
          
      - name: Run tests with Allure
        run: |
          mkdir -p allure-results
          
          # Create collections compatibility module
          cat > collections_compat.py << EOF
          """
          Python 3.10 Compatibility Layer for collections.Mapping
          
          This module provides compatibility for code that relies on collections.Mapping,
          which was removed in Python 3.10 in favor of collections.abc.Mapping.
          """
          
          import collections
          import collections.abc
          import sys
          
          # Apply patches for collections module
          if not hasattr(collections, 'Mapping'):
              collections.Mapping = collections.abc.Mapping
          
          if not hasattr(collections, 'Sequence'):
              collections.Sequence = collections.abc.Sequence
          
          print("Applied compatibility patches for collections module")
          EOF
          
          # Create test runner script that imports compatibility layer first
          cat > run_tests.py << EOF
          import sys
          import os
          
          # Import compatibility layer first
          import collections_compat
          
          # Import pytest and run tests
          import pytest
          
          # Create allure results directory
          if not os.path.exists("allure-results"):
              os.makedirs("allure-results")
          
          # Run pytest with allure reporting
          sys.exit(pytest.main(["tests/", "--alluredir=allure-results"]))
          EOF
          
          # Run tests with our compatibility layer
          python run_tests.py
        continue-on-error: true
        
      - name: Store Allure results
        if: always()
        run: |
          zip -r allure-results.zip allure-results/
          echo "Allure results zipped"
          
          # Create a simple HTML summary
          TOTAL=$(find allure-results -name "*.json" | grep -v "environment\|categories\|executor" | wc -l || echo 0)
          PASSED=$(grep -l '"status":"passed"' allure-results/*.json 2>/dev/null | wc -l || echo 0)
          FAILED=$((TOTAL - PASSED))
          
          cat > summary.html << EOF
          <!DOCTYPE html>
          <html>
          <head>
            <title>Test Results Summary</title>
            <style>
              body { font-family: Arial, sans-serif; margin: 20px; }
              .summary { display: flex; gap: 20px; margin-bottom: 20px; }
              .card { padding: 15px; border-radius: 8px; color: white; text-align: center; min-width: 100px; }
              .total { background-color: #2196F3; }
              .passed { background-color: #4CAF50; }
              .failed { background-color: #F44336; }
              .number { font-size: 24px; font-weight: bold; }
              .label { font-size: 14px; }
            </style>
          </head>
          <body>
            <h1>Test Results Summary</h1>
            <div class="summary">
              <div class="card total">
                <div class="number">\${TOTAL}</div>
                <div class="label">Total Tests</div>
              </div>
              <div class="card passed">
                <div class="number">\${PASSED}</div>
                <div class="label">Passed</div>
              </div>
              <div class="card failed">
                <div class="number">\${FAILED}</div>
                <div class="label">Failed</div>
              </div>
            </div>
            <p>Run ID: \${{ github.run_id }}</p>
            <p>Repository: \${{ github.repository }}</p>
            <p>Branch: \${{ github.ref }}</p>
            <p>Download the allure-results.zip artifact for detailed test results.</p>
          </body>
          </html>
          EOF
          
      - name: Upload Allure results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: allure-results
          path: allure-results.zip
          
      - name: Upload Summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: summary.html
          
      - name: Parse test metrics
        if: always()
        run: |
          echo "Parsing test metrics..."
          
          # Get test results from Allure JSON files
          TOTAL_TESTS=$(find allure-results -name "*.json" | grep -v "environment\|categories\|executor" | wc -l || echo 0)
          PASSED_TESTS=$(grep -l '"status":"passed"' allure-results/*.json 2>/dev/null | wc -l || echo 0)
          FAILED_TESTS=$((TOTAL_TESTS - PASSED_TESTS))
          
          # Calculate pass rate
          if [ $TOTAL_TESTS -eq 0 ]; then
            PASS_RATE=0
          else
            PASS_RATE=$(echo "scale=2; ($PASSED_TESTS * 100) / $TOTAL_TESTS" | bc)
          fi
          
          # Get critical tests count
          CRITICAL_TESTS=$(grep -l "critical_workflow" allure-results/*.json 2>/dev/null | wc -l || echo 0)
          
          # Get test duration from GitHub Actions timing
          START_TIME=$(date +%s)
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          # Create metrics JSON
          cat > metrics.json << EOF
          {
            "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "total_tests": $TOTAL_TESTS,
            "passed_tests": $PASSED_TESTS,
            "failed_tests": $FAILED_TESTS,
            "pass_rate": $PASS_RATE,
            "duration_seconds": $DURATION,
            "critical_tests_count": $CRITICAL_TESTS,
            "run_id": "\${{ github.run_id }}",
            "repository": "\${{ github.repository }}",
            "branch": "\${{ github.ref }}"
          }
          EOF
          
          cat metrics.json
          
      - name: Upload metrics artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: metrics
          path: metrics.json
          
      - name: Prepare metrics for deployment
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # Debug information
          echo "Current directory: $(pwd)"
          echo "Listing files: $(ls -la)"
          
          # Create metrics directory if it doesn't exist
          mkdir -p metrics
          
          # Copy current metrics to metrics directory with timestamp
          TIMESTAMP=$(date -u +"%Y%m%d%H%M%S")
          cp metrics.json metrics/metrics_${TIMESTAMP}.json
          
          # Create or update metrics index
          echo '{"files": ["metrics_'${TIMESTAMP}'.json"]}' > metrics/index.json
          
          # Create dashboard HTML in the metrics directory
          cat > metrics/dashboard.html << EOF
          <!DOCTYPE html>
          <html lang="en">
          <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Sanity Test Metrics Dashboard</title>
            <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
            <style>
              body { font-family: Arial, sans-serif; margin: 20px; }
              .dashboard { display: flex; flex-wrap: wrap; }
              .chart-container { width: 48%; margin: 1%; height: 300px; }
              .metrics-table { width: 98%; margin: 1%; }
              table { width: 100%; border-collapse: collapse; }
              th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
              th { background-color: #f2f2f2; }
              tr:nth-child(even) { background-color: #f9f9f9; }
              @media (max-width: 768px) {
                .chart-container { width: 98%; }
              }
            </style>
          </head>
          <body>
            <h1>Sanity Test Metrics Dashboard</h1>
            <div class="dashboard">
              <div class="chart-container">
                <canvas id="passRateChart"></canvas>
              </div>
              <div class="chart-container">
                <canvas id="durationChart"></canvas>
              </div>
              <div class="chart-container">
                <canvas id="testsChart"></canvas>
              </div>
              <div class="chart-container">
                <canvas id="criticalChart"></canvas>
              </div>
              <div class="metrics-table">
                <h2>Recent Test Runs</h2>
                <table id="metricsTable">
                  <thead>
                    <tr>
                      <th>Timestamp</th>
                      <th>Total Tests</th>
                      <th>Passed</th>
                      <th>Failed</th>
                      <th>Pass Rate</th>
                      <th>Duration (s)</th>
                      <th>Critical Tests</th>
                    </tr>
                  </thead>
                  <tbody id="tableBody"></tbody>
                </table>
              </div>
            </div>
            
            <script>
              // Fetch metrics data
              async function fetchMetrics() {
                try {
                  const indexResponse = await fetch('index.json');
                  const indexData = await indexResponse.json();
                  
                  const metricsData = [];
                  for (const file of indexData.files) {
                    const response = await fetch(file);
                    const data = await response.json();
                    metricsData.push(data);
                  }
                  
                  // Sort by timestamp
                  metricsData.sort((a, b) => new Date(a.timestamp) - new Date(b.timestamp));
                  
                  return metricsData;
                } catch (error) {
                  console.error('Error fetching metrics:', error);
                  return [];
                }
              }
              
              // Create charts
              async function createCharts() {
                const metricsData = await fetchMetrics();
                if (metricsData.length === 0) return;
                
                const timestamps = metricsData.map(d => {
                  const date = new Date(d.timestamp);
                  return date.toLocaleDateString() + ' ' + date.toLocaleTimeString();
                });
                
                // Pass Rate Chart
                new Chart(document.getElementById('passRateChart'), {
                  type: 'pie',
                  data: {
                    labels: ['Passed', 'Failed'],
                    datasets: [{
                      data: [
                        metricsData[metricsData.length-1].passed_tests,
                        metricsData[metricsData.length-1].failed_tests
                      ],
                      backgroundColor: ['#4CAF50', '#F44336']
                    }]
                  },
                  options: {
                    responsive: true,
                    plugins: {
                      title: {
                        display: true,
                        text: 'Latest Pass/Fail Rate'
                      }
                    }
                  }
                });
                
                // Duration Chart
                new Chart(document.getElementById('durationChart'), {
                  type: 'line',
                  data: {
                    labels: timestamps,
                    datasets: [{
                      label: 'Duration (seconds)',
                      data: metricsData.map(d => d.duration_seconds),
                      borderColor: '#2196F3',
                      tension: 0.1
                    }]
                  },
                  options: {
                    responsive: true,
                    plugins: {
                      title: {
                        display: true,
                        text: 'Test Duration Over Time'
                      }
                    }
                  }
                });
                
                // Tests Chart
                new Chart(document.getElementById('testsChart'), {
                  type: 'bar',
                  data: {
                    labels: timestamps,
                    datasets: [
                      {
                        label: 'Passed Tests',
                        data: metricsData.map(d => d.passed_tests),
                        backgroundColor: '#4CAF50'
                      },
                      {
                        label: 'Failed Tests',
                        data: metricsData.map(d => d.failed_tests),
                        backgroundColor: '#F44336'
                      }
                    ]
                  },
                  options: {
                    responsive: true,
                    plugins: {
                      title: {
                        display: true,
                        text: 'Test Results Over Time'
                      }
                    },
                    scales: {
                      x: {
                        stacked: true
                      },
                      y: {
                        stacked: true
                      }
                    }
                  }
                });
                
                // Critical Tests Chart
                new Chart(document.getElementById('criticalChart'), {
                  type: 'line',
                  data: {
                    labels: timestamps,
                    datasets: [{
                      label: 'Critical Tests',
                      data: metricsData.map(d => d.critical_tests_count),
                      borderColor: '#FF9800',
                      tension: 0.1
                    }]
                  },
                  options: {
                    responsive: true,
                    plugins: {
                      title: {
                        display: true,
                        text: 'Critical Tests Coverage'
                      }
                    }
                  }
                });
                
                // Populate table
                const tableBody = document.getElementById('tableBody');
                metricsData.slice(-10).reverse().forEach(metric => {
                  const row = document.createElement('tr');
                  
                  const date = new Date(metric.timestamp);
                  const formattedDate = date.toLocaleDateString() + ' ' + date.toLocaleTimeString();
                  
                  row.innerHTML = \`
                    <td>\${formattedDate}</td>
                    <td>\${metric.total_tests}</td>
                    <td>\${metric.passed_tests}</td>
                    <td>\${metric.failed_tests}</td>
                    <td>\${metric.pass_rate}%</td>
                    <td>\${metric.duration_seconds}</td>
                    <td>\${metric.critical_tests_count}</td>
                  \`;
                  
                  tableBody.appendChild(row);
                });
              }
              
              // Initialize dashboard
              createCharts();
            </script>
          </body>
          </html>
          EOF
          
          # Create a simple test file to verify deployment
          echo "Hello World" > metrics/test.txt
          
          # List the metrics directory to verify content
          echo "Metrics directory content:"
          ls -la metrics/
          
      - name: Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./metrics
          force_orphan: true
